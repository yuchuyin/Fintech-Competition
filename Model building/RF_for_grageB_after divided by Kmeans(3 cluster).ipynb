{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, glob, socket,random,csv,pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import Timer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "os.getcwd()\n",
    "os.chdir(r'D:/fintech/')\n",
    "path=os.getcwd()\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # B_LABEL=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_log_error as MSLE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import os, time, glob, socket\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "random.seed(123)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 0.7, 'n_estimators': 91}\n",
      "[0.72583942 0.73524255 0.73110721 0.73687298 0.73255132 0.73290473\n",
      " 0.72286306 0.72844198 0.73333333 0.71752577]\n"
     ]
    }
   ],
   "source": [
    "# B\n",
    "\n",
    "y_trainB=pd.read_csv(path+'/grade/B/label2/y_trainB_L0.csv',index_col=0)\n",
    "y_testB=pd.read_csv(path+'/grade/B/label2/y_testB_L0.csv',index_col=0)\n",
    "\n",
    "X_testB=pd.read_csv(path+'/grade/B/label2/X_testB_L0.csv',index_col=0)\n",
    "X_trainB=pd.read_csv(path+'/grade/B/label2/X_trainB_L0.csv',index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 處理 y\n",
    "le = LabelEncoder()\n",
    "le.fit(y_trainB['loan_status'].unique())  \n",
    "y_trainB['ans']=le.transform(y_trainB['loan_status'])\n",
    "\n",
    "#drop id\n",
    "\n",
    "X_trainB.drop(columns=['Unnamed: 0.1'])\n",
    "X_testB.drop(columns=['Unnamed: 0.1'])\n",
    "\n",
    "##\n",
    "\n",
    "gsc = GridSearchCV(estimator=RandomForestClassifier(),param_grid={\n",
    "            'max_features':['sqrt','auto','log2',0.5,0.7],\n",
    "            'max_depth': range(1,6),\n",
    "            'n_estimators': range(1,101,10)},\n",
    "             cv=10, scoring='f1',verbose=0,n_jobs=-1,)\n",
    "\n",
    "grid_result = gsc.fit(X_trainB,y_trainB.ans)\n",
    "best_params = grid_result.best_params_\n",
    "print(best_params)\n",
    "\n",
    "rfr = RandomForestClassifier(\n",
    "    max_depth=best_params[\"max_depth\"], \n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=False, verbose=False)\n",
    "\n",
    "scores = cross_val_score(rfr, X_trainB,y_trainB.ans, cv=10, scoring='f1')\n",
    "print(scores)\n",
    "\n",
    "rfr.fit(X_trainB,y_trainB.ans)\n",
    "\n",
    "\n",
    "# save model\n",
    "#儲存Model(注:save資料夾要預先建立，否則會報錯)\n",
    "\n",
    "with open( path+'\\grade\\B\\label2\\RF_B_L0.pickle', 'wb') as f:\n",
    "    pickle.dump(rfr, f)\n",
    "\n",
    "#讀取Model\n",
    "#with open('save/clf.pickle', 'rb') as f:\n",
    "#    clf2 = pickle.load(f)\n",
    "    #測試讀取後的Model\n",
    "#   print(clf2.predict(X[0:1]))\n",
    "\n",
    "## predict_y\n",
    "\n",
    "rf_1_pred=rfr.predict(X_testB)\n",
    "\n",
    "y_ans = pd.DataFrame(rf_1_pred,columns=['predict'],index=y_testB.index)\n",
    "y_output=pd.merge(y_testB,y_ans,left_index=True,right_index=True)\n",
    "y_output.to_csv(path+'\\grade\\B\\label2\\y_output_rf_B_L0.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
