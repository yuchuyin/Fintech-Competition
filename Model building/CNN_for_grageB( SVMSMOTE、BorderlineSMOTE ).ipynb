{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics,ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error as MSLE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "random.seed(123)\n",
    "#pd.set_option(\"display.max_columns\", None)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm \n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "import os, time, glob, socket,random,csv,pickle\n",
    "import pandas as pd\n",
    "\n",
    "from timeit import Timer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "os.getcwd()\n",
    "os.chdir(r'D:/fintech/')\n",
    "path=os.getcwd()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "X_train_more\n",
    "X_test_more\n",
    "y_train\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# mlp\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras import Sequential\n",
    "import keras\n",
    "from keras.models import Sequential    #匯入線性堆疊模型之模組\n",
    "from keras.layers import Dense\n",
    "from keras import metrics#匯入緊密連接模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.read_csv(path+'/grade/B/y_trainB.csv',index_col=0)\n",
    "y_test=pd.read_csv(path+'/grade/B/y_testB.csv',index_col=0)\n",
    "X_train_more=pd.read_csv(path+'/grade/B/X_train_more.csv',index_col=0)\n",
    "X_test_more=pd.read_csv(path+'/grade/B/X_test_more.csv',index_col=0)\n",
    "\n",
    "X_train_more=X_train_more.drop(columns=['Unnamed: 0.1'])\n",
    "X_test_more=X_test_more.drop(columns=['Unnamed: 0.1'])\n",
    "\n",
    "# 處理 y\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train['loan_status'].unique())  \n",
    "y_train['ans']=le.transform(y_train['loan_status'])\n",
    "\n",
    "X_train_more = X_train_more.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '',x))\n",
    "X_test_more = X_test_more.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '',x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3=pd.read_csv(path+'/grade/B/X4.csv',index_col=0)\n",
    "y3=pd.read_csv(path+'/grade/B/y4.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分 train0 test0\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X_train_more, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0=X3\n",
    "y_train0=y3\n",
    "y_train0_0 = keras.utils.to_categorical(y_train0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(887721, 82)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model01 = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model01.add(Dense(84, activation='relu', input_shape=(82,)))\n",
    "\n",
    "# Add one hidden layer \n",
    "model01.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model01.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 621404 samples, validate on 266317 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 0.0976 - f1_m: 0.9659 - val_loss: 0.1447 - val_f1_m: 0.9421\n",
      "Epoch 2/100\n",
      " - 8s - loss: 0.0626 - f1_m: 0.9795 - val_loss: 0.0587 - val_f1_m: 0.9788\n",
      "Epoch 3/100\n",
      " - 7s - loss: 0.0522 - f1_m: 0.9835 - val_loss: 0.0737 - val_f1_m: 0.9741\n",
      "Epoch 4/100\n",
      " - 7s - loss: 0.0466 - f1_m: 0.9855 - val_loss: 0.0507 - val_f1_m: 0.9803\n",
      "Epoch 5/100\n",
      " - 7s - loss: 0.0433 - f1_m: 0.9866 - val_loss: 0.0550 - val_f1_m: 0.9808\n",
      "Epoch 6/100\n",
      " - 7s - loss: 0.0411 - f1_m: 0.9874 - val_loss: 0.0509 - val_f1_m: 0.9824\n",
      "Epoch 7/100\n",
      " - 7s - loss: 0.0394 - f1_m: 0.9881 - val_loss: 0.0728 - val_f1_m: 0.9745\n",
      "Epoch 8/100\n",
      " - 7s - loss: 0.0385 - f1_m: 0.9883 - val_loss: 0.0448 - val_f1_m: 0.9835\n",
      "Epoch 9/100\n",
      " - 7s - loss: 0.0377 - f1_m: 0.9886 - val_loss: 0.0544 - val_f1_m: 0.9801\n",
      "Epoch 10/100\n",
      " - 8s - loss: 0.0368 - f1_m: 0.9890 - val_loss: 0.0545 - val_f1_m: 0.9807\n",
      "Epoch 11/100\n",
      " - 7s - loss: 0.0369 - f1_m: 0.9889 - val_loss: 0.0656 - val_f1_m: 0.9768\n",
      "Epoch 12/100\n",
      " - 7s - loss: 0.0363 - f1_m: 0.9890 - val_loss: 0.0725 - val_f1_m: 0.9747\n",
      "Epoch 13/100\n",
      " - 7s - loss: 0.0364 - f1_m: 0.9891 - val_loss: 0.0459 - val_f1_m: 0.9831\n",
      "Epoch 14/100\n",
      " - 7s - loss: 0.0362 - f1_m: 0.9892 - val_loss: 0.0419 - val_f1_m: 0.9842\n",
      "Epoch 15/100\n",
      " - 7s - loss: 0.0360 - f1_m: 0.9893 - val_loss: 0.0511 - val_f1_m: 0.9831\n",
      "Epoch 16/100\n",
      " - 7s - loss: 0.0362 - f1_m: 0.9893 - val_loss: 0.0433 - val_f1_m: 0.9858\n",
      "Epoch 17/100\n",
      " - 7s - loss: 0.0360 - f1_m: 0.9894 - val_loss: 0.0701 - val_f1_m: 0.9769\n",
      "Epoch 18/100\n",
      " - 7s - loss: 0.0360 - f1_m: 0.9894 - val_loss: 0.0474 - val_f1_m: 0.9829\n",
      "Epoch 19/100\n",
      " - 8s - loss: 0.0354 - f1_m: 0.9896 - val_loss: 0.0493 - val_f1_m: 0.9840\n",
      "Epoch 20/100\n",
      " - 7s - loss: 0.0354 - f1_m: 0.9895 - val_loss: 0.0468 - val_f1_m: 0.9847\n",
      "Epoch 21/100\n",
      " - 7s - loss: 0.0354 - f1_m: 0.9895 - val_loss: 0.0592 - val_f1_m: 0.9796\n",
      "Epoch 22/100\n",
      " - 7s - loss: 0.0356 - f1_m: 0.9896 - val_loss: 0.0508 - val_f1_m: 0.9826\n",
      "Epoch 23/100\n",
      " - 7s - loss: 0.0353 - f1_m: 0.9897 - val_loss: 0.0624 - val_f1_m: 0.9777\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.0353 - f1_m: 0.9897 - val_loss: 0.0524 - val_f1_m: 0.9817\n",
      "Epoch 25/100\n",
      " - 7s - loss: 0.0349 - f1_m: 0.9897 - val_loss: 0.0535 - val_f1_m: 0.9817\n",
      "Epoch 26/100\n",
      " - 7s - loss: 0.0350 - f1_m: 0.9899 - val_loss: 0.0556 - val_f1_m: 0.9804\n",
      "Epoch 27/100\n",
      " - 7s - loss: 0.0350 - f1_m: 0.9898 - val_loss: 0.0229 - val_f1_m: 0.9912\n",
      "Epoch 28/100\n",
      " - 7s - loss: 0.0349 - f1_m: 0.9898 - val_loss: 0.0349 - val_f1_m: 0.9871\n",
      "Epoch 29/100\n",
      " - 7s - loss: 0.0347 - f1_m: 0.9897 - val_loss: 0.0436 - val_f1_m: 0.9828\n",
      "Epoch 30/100\n",
      " - 7s - loss: 0.0352 - f1_m: 0.9899 - val_loss: 0.0678 - val_f1_m: 0.9787\n",
      "Epoch 31/100\n",
      " - 7s - loss: 0.0347 - f1_m: 0.9900 - val_loss: 0.0527 - val_f1_m: 0.9822\n",
      "Epoch 32/100\n",
      " - 7s - loss: 0.0347 - f1_m: 0.9901 - val_loss: 0.0636 - val_f1_m: 0.9781\n",
      "Epoch 33/100\n",
      " - 7s - loss: 0.0351 - f1_m: 0.9901 - val_loss: 0.0472 - val_f1_m: 0.9853\n",
      "Epoch 34/100\n",
      " - 7s - loss: 0.0349 - f1_m: 0.9899 - val_loss: 0.0509 - val_f1_m: 0.9820\n",
      "Epoch 35/100\n",
      " - 7s - loss: 0.0357 - f1_m: 0.9899 - val_loss: 0.0598 - val_f1_m: 0.9786\n",
      "Epoch 36/100\n",
      " - 7s - loss: 0.0352 - f1_m: 0.9900 - val_loss: 0.0469 - val_f1_m: 0.9832\n",
      "Epoch 37/100\n",
      " - 7s - loss: 0.0352 - f1_m: 0.9901 - val_loss: 0.0596 - val_f1_m: 0.9827\n",
      "Epoch 38/100\n",
      " - 7s - loss: 0.0359 - f1_m: 0.9899 - val_loss: 0.0663 - val_f1_m: 0.9798\n",
      "Epoch 39/100\n",
      " - 7s - loss: 0.0362 - f1_m: 0.9899 - val_loss: 0.0515 - val_f1_m: 0.9831\n",
      "Epoch 40/100\n",
      " - 7s - loss: 0.0358 - f1_m: 0.9900 - val_loss: 0.0597 - val_f1_m: 0.9808\n",
      "Epoch 41/100\n",
      " - 7s - loss: 0.0360 - f1_m: 0.9899 - val_loss: 0.0607 - val_f1_m: 0.9797\n",
      "Epoch 42/100\n",
      " - 7s - loss: 0.0360 - f1_m: 0.9900 - val_loss: 0.0337 - val_f1_m: 0.9876\n",
      "Epoch 43/100\n",
      " - 7s - loss: 0.0360 - f1_m: 0.9900 - val_loss: 0.0485 - val_f1_m: 0.9842\n",
      "Epoch 44/100\n",
      " - 7s - loss: 0.0362 - f1_m: 0.9899 - val_loss: 0.0563 - val_f1_m: 0.9826\n",
      "Epoch 45/100\n",
      " - 7s - loss: 0.0364 - f1_m: 0.9899 - val_loss: 0.0409 - val_f1_m: 0.9860\n",
      "Epoch 46/100\n",
      " - 7s - loss: 0.0363 - f1_m: 0.9898 - val_loss: 0.0615 - val_f1_m: 0.9804\n",
      "Epoch 47/100\n",
      " - 7s - loss: 0.0361 - f1_m: 0.9899 - val_loss: 0.0669 - val_f1_m: 0.9816\n",
      "Epoch 48/100\n",
      " - 7s - loss: 0.0361 - f1_m: 0.9899 - val_loss: 0.0578 - val_f1_m: 0.9799\n",
      "Epoch 49/100\n",
      " - 7s - loss: 0.0367 - f1_m: 0.9898 - val_loss: 0.0478 - val_f1_m: 0.9823\n",
      "Epoch 50/100\n",
      " - 7s - loss: 0.0365 - f1_m: 0.9898 - val_loss: 0.0699 - val_f1_m: 0.9804\n",
      "Epoch 51/100\n",
      " - 8s - loss: 0.0363 - f1_m: 0.9898 - val_loss: 0.0502 - val_f1_m: 0.9834\n",
      "Epoch 52/100\n",
      " - 8s - loss: 0.0366 - f1_m: 0.9899 - val_loss: 0.0654 - val_f1_m: 0.9829\n",
      "Epoch 53/100\n",
      " - 7s - loss: 0.0361 - f1_m: 0.9898 - val_loss: 0.0511 - val_f1_m: 0.9843\n",
      "Epoch 54/100\n",
      " - 7s - loss: 0.0369 - f1_m: 0.9899 - val_loss: 0.0455 - val_f1_m: 0.9855\n",
      "Epoch 55/100\n",
      " - 7s - loss: 0.0365 - f1_m: 0.9900 - val_loss: 0.0475 - val_f1_m: 0.9840\n",
      "Epoch 56/100\n",
      " - 7s - loss: 0.0362 - f1_m: 0.9900 - val_loss: 0.0631 - val_f1_m: 0.9810\n",
      "Epoch 57/100\n",
      " - 8s - loss: 0.0365 - f1_m: 0.9899 - val_loss: 0.0478 - val_f1_m: 0.9849\n",
      "Epoch 58/100\n",
      " - 7s - loss: 0.0361 - f1_m: 0.9900 - val_loss: 0.0546 - val_f1_m: 0.9809\n",
      "Epoch 59/100\n",
      " - 7s - loss: 0.0361 - f1_m: 0.9901 - val_loss: 0.0619 - val_f1_m: 0.9814\n",
      "Epoch 60/100\n",
      " - 7s - loss: 0.0365 - f1_m: 0.9900 - val_loss: 0.0632 - val_f1_m: 0.9797\n",
      "Epoch 61/100\n",
      " - 7s - loss: 0.0364 - f1_m: 0.9901 - val_loss: 0.0501 - val_f1_m: 0.9862\n",
      "Epoch 62/100\n",
      " - 7s - loss: 0.0358 - f1_m: 0.9901 - val_loss: 0.0412 - val_f1_m: 0.9858\n",
      "Epoch 63/100\n",
      " - 7s - loss: 0.0359 - f1_m: 0.9902 - val_loss: 0.0416 - val_f1_m: 0.9847\n",
      "Epoch 64/100\n",
      " - 7s - loss: 0.0358 - f1_m: 0.9902 - val_loss: 0.0475 - val_f1_m: 0.9829\n",
      "Epoch 65/100\n",
      " - 7s - loss: 0.0358 - f1_m: 0.9902 - val_loss: 0.0487 - val_f1_m: 0.9831\n",
      "Epoch 66/100\n",
      " - 7s - loss: 0.0360 - f1_m: 0.9902 - val_loss: 0.0475 - val_f1_m: 0.9841\n",
      "Epoch 67/100\n",
      " - 7s - loss: 0.0360 - f1_m: 0.9901 - val_loss: 0.0677 - val_f1_m: 0.9816\n",
      "Epoch 68/100\n",
      " - 7s - loss: 0.0365 - f1_m: 0.9901 - val_loss: 0.0327 - val_f1_m: 0.9886\n",
      "Epoch 69/100\n",
      " - 7s - loss: 0.0362 - f1_m: 0.9902 - val_loss: 0.0616 - val_f1_m: 0.9800\n",
      "Epoch 70/100\n",
      " - 7s - loss: 0.0363 - f1_m: 0.9903 - val_loss: 0.0475 - val_f1_m: 0.9850\n",
      "Epoch 71/100\n",
      " - 7s - loss: 0.0363 - f1_m: 0.9901 - val_loss: 0.0716 - val_f1_m: 0.9785\n",
      "Epoch 72/100\n",
      " - 7s - loss: 0.0365 - f1_m: 0.9901 - val_loss: 0.0545 - val_f1_m: 0.9836\n",
      "Epoch 73/100\n",
      " - 7s - loss: 0.0366 - f1_m: 0.9901 - val_loss: 0.0559 - val_f1_m: 0.9820\n",
      "Epoch 74/100\n",
      " - 7s - loss: 0.0365 - f1_m: 0.9900 - val_loss: 0.0532 - val_f1_m: 0.9830\n",
      "Epoch 75/100\n",
      " - 7s - loss: 0.0368 - f1_m: 0.9900 - val_loss: 0.0620 - val_f1_m: 0.9825\n",
      "Epoch 76/100\n",
      " - 7s - loss: 0.0366 - f1_m: 0.9899 - val_loss: 0.0574 - val_f1_m: 0.9809\n",
      "Epoch 77/100\n",
      " - 7s - loss: 0.0366 - f1_m: 0.9901 - val_loss: 0.0655 - val_f1_m: 0.9814\n",
      "Epoch 78/100\n",
      " - 7s - loss: 0.0365 - f1_m: 0.9900 - val_loss: 0.0494 - val_f1_m: 0.9841\n",
      "Epoch 79/100\n",
      " - 7s - loss: 0.0367 - f1_m: 0.9899 - val_loss: 0.0681 - val_f1_m: 0.9808\n",
      "Epoch 80/100\n",
      " - 7s - loss: 0.0368 - f1_m: 0.9900 - val_loss: 0.0469 - val_f1_m: 0.9836\n",
      "Epoch 81/100\n",
      " - 7s - loss: 0.0367 - f1_m: 0.9898 - val_loss: 0.0555 - val_f1_m: 0.9840\n",
      "Epoch 82/100\n",
      " - 7s - loss: 0.0374 - f1_m: 0.9901 - val_loss: 0.0719 - val_f1_m: 0.9798\n",
      "Epoch 83/100\n",
      " - 7s - loss: 0.0369 - f1_m: 0.9900 - val_loss: 0.0597 - val_f1_m: 0.9813\n",
      "Epoch 84/100\n",
      " - 7s - loss: 0.0369 - f1_m: 0.9900 - val_loss: 0.0586 - val_f1_m: 0.9850\n",
      "Epoch 85/100\n",
      " - 7s - loss: 0.0372 - f1_m: 0.9901 - val_loss: 0.0489 - val_f1_m: 0.9840\n",
      "Epoch 86/100\n",
      " - 7s - loss: 0.0376 - f1_m: 0.9899 - val_loss: 0.0568 - val_f1_m: 0.9814\n",
      "Epoch 87/100\n",
      " - 7s - loss: 0.0372 - f1_m: 0.9898 - val_loss: 0.0719 - val_f1_m: 0.9758\n",
      "Epoch 88/100\n",
      " - 7s - loss: 0.0377 - f1_m: 0.9899 - val_loss: 0.0620 - val_f1_m: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      " - 7s - loss: 0.0375 - f1_m: 0.9899 - val_loss: 0.0554 - val_f1_m: 0.9805\n",
      "Epoch 90/100\n",
      " - 7s - loss: 0.0373 - f1_m: 0.9898 - val_loss: 0.0530 - val_f1_m: 0.9816\n",
      "Epoch 91/100\n",
      " - 7s - loss: 0.0376 - f1_m: 0.9898 - val_loss: 0.0519 - val_f1_m: 0.9821\n",
      "Epoch 92/100\n",
      " - 7s - loss: 0.0376 - f1_m: 0.9897 - val_loss: 0.0598 - val_f1_m: 0.9797\n",
      "Epoch 93/100\n",
      " - 7s - loss: 0.0382 - f1_m: 0.9897 - val_loss: 0.0432 - val_f1_m: 0.9855\n",
      "Epoch 94/100\n",
      " - 7s - loss: 0.0379 - f1_m: 0.9897 - val_loss: 0.0488 - val_f1_m: 0.9837\n",
      "Epoch 95/100\n",
      " - 7s - loss: 0.0381 - f1_m: 0.9897 - val_loss: 0.0455 - val_f1_m: 0.9845\n",
      "Epoch 96/100\n",
      " - 7s - loss: 0.0384 - f1_m: 0.9895 - val_loss: 0.0692 - val_f1_m: 0.9761\n",
      "Epoch 97/100\n",
      " - 7s - loss: 0.0383 - f1_m: 0.9897 - val_loss: 0.0555 - val_f1_m: 0.9825\n",
      "Epoch 98/100\n",
      " - 8s - loss: 0.0384 - f1_m: 0.9896 - val_loss: 0.0640 - val_f1_m: 0.9788\n",
      "Epoch 99/100\n",
      " - 8s - loss: 0.0392 - f1_m: 0.9895 - val_loss: 0.0544 - val_f1_m: 0.9809\n",
      "Epoch 100/100\n",
      " - 7s - loss: 0.0388 - f1_m: 0.9894 - val_loss: 0.0392 - val_f1_m: 0.9855\n"
     ]
    }
   ],
   "source": [
    "model01.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "               metrics=[f1_m])\n",
    "\n",
    "train_history=model01.fit(X_train0, y_train0_0, validation_split=0.3, epochs=100, batch_size=200, verbose=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9302590378593795\n",
      "0.986155286823708\n"
     ]
    }
   ],
   "source": [
    "prediction=model01.predict_classes(X_test0) \n",
    "\n",
    "y_true=y_test0.ans\n",
    "print(f1_score(y_true, prediction, average='binary'))\n",
    "print(accuracy_score(y_true, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict Y\n",
    "y_pred=model01.predict_classes(X_test_more)\n",
    "y_ans = pd.DataFrame(y_pred,columns=['predict'],index=y_test.index)\n",
    "y_output=pd.merge(y_test,y_ans,left_index=True,right_index=True)\n",
    "\n",
    "y_output.to_csv(path+'\\grade\\B\\y_output_MLP_B_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=82, units=48)`\n",
      "  \n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=48, units=48)`\n",
      "  \"\"\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=48, units=36)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=36, units=36)`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=36, units=12)`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=12, units=12)`\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=12, units=2)`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() #建立模型\n",
    "model.add(Dense(input_dim = X_train0.shape[1], output_dim = 48)) #添加输入层、隐藏层的连接\n",
    "model.add(Activation('tanh')) #以Relu函数为激活函数\n",
    "\n",
    "model.add(Dense(input_dim = 48, output_dim = 48)) #添加隐藏层、隐藏层的连接\n",
    "model.add(Activation('relu')) #以Relu函数为激活函数\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(input_dim = 48, output_dim = 36)) #添加隐藏层、隐藏层的连接\n",
    "model.add(Activation('relu')) #以Relu函数为激活函数\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(input_dim = 36, output_dim = 36)) #添加隐藏层、隐藏层的连接\n",
    "model.add(Activation('relu')) #以Relu函数为激活函数\n",
    "\n",
    "model.add(Dense(input_dim = 36, output_dim = 12)) #添加隐藏层、隐藏层的连接\n",
    "model.add(Activation('relu')) #以Relu函数为激活函数\n",
    "model.add(Dense(input_dim = 12, output_dim = 12)) #添加隐藏层、隐藏层的连接\n",
    "model.add(Activation('relu')) #以Relu函数为激活函数\n",
    "\n",
    "\n",
    "model.add(Dense(input_dim = 12, output_dim = 2)) #添加隐藏层、输出层的连接\n",
    "model.add(Activation('sigmoid')) #以sigmoid函数为激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 621404 samples, validate on 266317 samples\n",
      "Epoch 1/100\n",
      " - 10s - loss: 0.1088 - f1_m: 0.9609 - val_loss: 0.0974 - val_f1_m: 0.9583\n",
      "Epoch 2/100\n",
      " - 10s - loss: 0.0694 - f1_m: 0.9776 - val_loss: 0.0810 - val_f1_m: 0.9665\n",
      "Epoch 3/100\n",
      " - 10s - loss: 0.0600 - f1_m: 0.9810 - val_loss: 0.0862 - val_f1_m: 0.9613\n",
      "Epoch 4/100\n",
      " - 10s - loss: 0.0550 - f1_m: 0.9829 - val_loss: 0.0465 - val_f1_m: 0.9799\n",
      "Epoch 5/100\n",
      " - 11s - loss: 0.0522 - f1_m: 0.9839 - val_loss: 0.0567 - val_f1_m: 0.9782\n",
      "Epoch 6/100\n",
      " - 11s - loss: 0.0501 - f1_m: 0.9846 - val_loss: 0.0668 - val_f1_m: 0.9735\n",
      "Epoch 7/100\n",
      " - 10s - loss: 0.0488 - f1_m: 0.9850 - val_loss: 0.0429 - val_f1_m: 0.9830\n",
      "Epoch 8/100\n",
      " - 11s - loss: 0.0479 - f1_m: 0.9854 - val_loss: 0.0555 - val_f1_m: 0.9814\n",
      "Epoch 9/100\n",
      " - 12s - loss: 0.0471 - f1_m: 0.9856 - val_loss: 0.0425 - val_f1_m: 0.9821\n",
      "Epoch 10/100\n",
      " - 12s - loss: 0.0461 - f1_m: 0.9861 - val_loss: 0.0386 - val_f1_m: 0.9865\n",
      "Epoch 11/100\n",
      " - 11s - loss: 0.0461 - f1_m: 0.9861 - val_loss: 0.0504 - val_f1_m: 0.9816\n",
      "Epoch 12/100\n",
      " - 10s - loss: 0.0457 - f1_m: 0.9863 - val_loss: 0.0596 - val_f1_m: 0.9776\n",
      "Epoch 13/100\n",
      " - 11s - loss: 0.0457 - f1_m: 0.9863 - val_loss: 0.0450 - val_f1_m: 0.9851\n",
      "Epoch 14/100\n",
      " - 10s - loss: 0.0449 - f1_m: 0.9865 - val_loss: 0.0549 - val_f1_m: 0.9794\n",
      "Epoch 15/100\n",
      " - 11s - loss: 0.0446 - f1_m: 0.9869 - val_loss: 0.0519 - val_f1_m: 0.9806\n",
      "Epoch 16/100\n",
      " - 13s - loss: 0.0444 - f1_m: 0.9869 - val_loss: 0.0470 - val_f1_m: 0.9819\n",
      "Epoch 17/100\n",
      " - 11s - loss: 0.0436 - f1_m: 0.9872 - val_loss: 0.0621 - val_f1_m: 0.9765\n",
      "Epoch 18/100\n",
      " - 10s - loss: 0.0430 - f1_m: 0.9875 - val_loss: 0.0384 - val_f1_m: 0.9861\n",
      "Epoch 19/100\n",
      " - 11s - loss: 0.0422 - f1_m: 0.9876 - val_loss: 0.0471 - val_f1_m: 0.9833\n",
      "Epoch 20/100\n",
      " - 16s - loss: 0.0417 - f1_m: 0.9878 - val_loss: 0.0330 - val_f1_m: 0.9878\n",
      "Epoch 21/100\n",
      " - 14s - loss: 0.0414 - f1_m: 0.9880 - val_loss: 0.0352 - val_f1_m: 0.9872\n",
      "Epoch 22/100\n",
      " - 18s - loss: 0.0415 - f1_m: 0.9878 - val_loss: 0.0436 - val_f1_m: 0.9841\n",
      "Epoch 23/100\n",
      " - 21s - loss: 0.0409 - f1_m: 0.9880 - val_loss: 0.0444 - val_f1_m: 0.9842\n",
      "Epoch 24/100\n",
      " - 21s - loss: 0.0409 - f1_m: 0.9881 - val_loss: 0.0398 - val_f1_m: 0.9859\n",
      "Epoch 25/100\n",
      " - 20s - loss: 0.0407 - f1_m: 0.9882 - val_loss: 0.0479 - val_f1_m: 0.9825\n",
      "Epoch 26/100\n",
      " - 20s - loss: 0.0407 - f1_m: 0.9884 - val_loss: 0.0368 - val_f1_m: 0.9850\n",
      "Epoch 27/100\n",
      " - 20s - loss: 0.0409 - f1_m: 0.9883 - val_loss: 0.0434 - val_f1_m: 0.9850\n",
      "Epoch 28/100\n",
      " - 20s - loss: 0.0409 - f1_m: 0.9882 - val_loss: 0.0445 - val_f1_m: 0.9831\n",
      "Epoch 29/100\n",
      " - 20s - loss: 0.0413 - f1_m: 0.9882 - val_loss: 0.0508 - val_f1_m: 0.9830\n",
      "Epoch 30/100\n",
      " - 19s - loss: 0.0410 - f1_m: 0.9882 - val_loss: 0.0501 - val_f1_m: 0.9818\n",
      "Epoch 31/100\n",
      " - 20s - loss: 0.0418 - f1_m: 0.9880 - val_loss: 0.0224 - val_f1_m: 0.9911\n",
      "Epoch 32/100\n",
      " - 19s - loss: 0.0412 - f1_m: 0.9880 - val_loss: 0.0387 - val_f1_m: 0.9836\n",
      "Epoch 33/100\n",
      " - 19s - loss: 0.0412 - f1_m: 0.9883 - val_loss: 0.0411 - val_f1_m: 0.9864\n",
      "Epoch 34/100\n",
      " - 20s - loss: 0.0417 - f1_m: 0.9881 - val_loss: 0.0422 - val_f1_m: 0.9866\n",
      "Epoch 35/100\n",
      " - 19s - loss: 0.0419 - f1_m: 0.9881 - val_loss: 0.0411 - val_f1_m: 0.9862\n",
      "Epoch 36/100\n",
      " - 19s - loss: 0.0421 - f1_m: 0.9880 - val_loss: 0.0445 - val_f1_m: 0.9841\n",
      "Epoch 37/100\n",
      " - 19s - loss: 0.0422 - f1_m: 0.9881 - val_loss: 0.0412 - val_f1_m: 0.9855\n",
      "Epoch 38/100\n",
      " - 18s - loss: 0.0416 - f1_m: 0.9882 - val_loss: 0.0588 - val_f1_m: 0.9812\n",
      "Epoch 39/100\n",
      " - 19s - loss: 0.0413 - f1_m: 0.9883 - val_loss: 0.0471 - val_f1_m: 0.9835\n",
      "Epoch 40/100\n",
      " - 20s - loss: 0.0413 - f1_m: 0.9884 - val_loss: 0.0377 - val_f1_m: 0.9864\n",
      "Epoch 41/100\n",
      " - 20s - loss: 0.0410 - f1_m: 0.9883 - val_loss: 0.0464 - val_f1_m: 0.9799\n",
      "Epoch 42/100\n",
      " - 20s - loss: 0.0411 - f1_m: 0.9884 - val_loss: 0.0509 - val_f1_m: 0.9800\n",
      "Epoch 43/100\n",
      " - 14s - loss: 0.0409 - f1_m: 0.9883 - val_loss: 0.0434 - val_f1_m: 0.9839\n",
      "Epoch 44/100\n",
      " - 11s - loss: 0.0405 - f1_m: 0.9885 - val_loss: 0.0256 - val_f1_m: 0.9913\n",
      "Epoch 45/100\n",
      " - 14s - loss: 0.0408 - f1_m: 0.9884 - val_loss: 0.0646 - val_f1_m: 0.9741\n",
      "Epoch 46/100\n",
      " - 12s - loss: 0.0411 - f1_m: 0.9883 - val_loss: 0.0469 - val_f1_m: 0.9808\n",
      "Epoch 47/100\n",
      " - 13s - loss: 0.0409 - f1_m: 0.9884 - val_loss: 0.0287 - val_f1_m: 0.9882\n",
      "Epoch 48/100\n",
      " - 12s - loss: 0.0413 - f1_m: 0.9885 - val_loss: 0.0294 - val_f1_m: 0.9883\n",
      "Epoch 49/100\n",
      " - 11s - loss: 0.0416 - f1_m: 0.9884 - val_loss: 0.0393 - val_f1_m: 0.9875\n",
      "Epoch 50/100\n",
      " - 12s - loss: 0.0421 - f1_m: 0.9881 - val_loss: 0.0428 - val_f1_m: 0.9850\n",
      "Epoch 51/100\n",
      " - 11s - loss: 0.0423 - f1_m: 0.9881 - val_loss: 0.0378 - val_f1_m: 0.9867\n",
      "Epoch 52/100\n",
      " - 11s - loss: 0.0424 - f1_m: 0.9882 - val_loss: 0.0480 - val_f1_m: 0.9841\n",
      "Epoch 53/100\n",
      " - 13s - loss: 0.0419 - f1_m: 0.9883 - val_loss: 0.0499 - val_f1_m: 0.9833\n",
      "Epoch 54/100\n",
      " - 11s - loss: 0.0423 - f1_m: 0.9884 - val_loss: 0.0591 - val_f1_m: 0.9809\n",
      "Epoch 55/100\n",
      " - 11s - loss: 0.0422 - f1_m: 0.9883 - val_loss: 0.0484 - val_f1_m: 0.9826\n",
      "Epoch 56/100\n",
      " - 12s - loss: 0.0428 - f1_m: 0.9884 - val_loss: 0.0321 - val_f1_m: 0.9891\n",
      "Epoch 57/100\n",
      " - 13s - loss: 0.0426 - f1_m: 0.9883 - val_loss: 0.0394 - val_f1_m: 0.9861\n",
      "Epoch 58/100\n",
      " - 12s - loss: 0.0416 - f1_m: 0.9883 - val_loss: 0.0496 - val_f1_m: 0.9820\n",
      "Epoch 59/100\n",
      " - 11s - loss: 0.0416 - f1_m: 0.9885 - val_loss: 0.0417 - val_f1_m: 0.9863\n",
      "Epoch 60/100\n",
      " - 10s - loss: 0.0420 - f1_m: 0.9883 - val_loss: 0.0470 - val_f1_m: 0.9812\n",
      "Epoch 61/100\n",
      " - 11s - loss: 0.0429 - f1_m: 0.9884 - val_loss: 0.0512 - val_f1_m: 0.9815\n",
      "Epoch 62/100\n",
      " - 11s - loss: 0.0426 - f1_m: 0.9883 - val_loss: 0.0493 - val_f1_m: 0.9832\n",
      "Epoch 63/100\n",
      " - 12s - loss: 0.0432 - f1_m: 0.9883 - val_loss: 0.0423 - val_f1_m: 0.9837\n",
      "Epoch 64/100\n",
      " - 13s - loss: 0.0431 - f1_m: 0.9883 - val_loss: 0.0328 - val_f1_m: 0.9882\n",
      "Epoch 65/100\n",
      " - 12s - loss: 0.0441 - f1_m: 0.9882 - val_loss: 0.0520 - val_f1_m: 0.9819\n",
      "Epoch 66/100\n",
      " - 11s - loss: 0.0436 - f1_m: 0.9882 - val_loss: 0.0582 - val_f1_m: 0.9780\n",
      "Epoch 67/100\n",
      " - 10s - loss: 0.0451 - f1_m: 0.9881 - val_loss: 0.0474 - val_f1_m: 0.9829\n",
      "Epoch 68/100\n",
      " - 10s - loss: 0.0443 - f1_m: 0.9882 - val_loss: 0.0550 - val_f1_m: 0.9833\n",
      "Epoch 69/100\n",
      " - 10s - loss: 0.0439 - f1_m: 0.9879 - val_loss: 0.0373 - val_f1_m: 0.9868\n",
      "Epoch 70/100\n",
      " - 11s - loss: 0.0446 - f1_m: 0.9877 - val_loss: 0.0435 - val_f1_m: 0.9869\n",
      "Epoch 71/100\n",
      " - 18s - loss: 0.0449 - f1_m: 0.9878 - val_loss: 0.0587 - val_f1_m: 0.9755\n",
      "Epoch 72/100\n",
      " - 18s - loss: 0.0463 - f1_m: 0.9877 - val_loss: 0.0654 - val_f1_m: 0.9770\n",
      "Epoch 73/100\n",
      " - 11s - loss: 0.0451 - f1_m: 0.9877 - val_loss: 0.0516 - val_f1_m: 0.9842\n",
      "Epoch 74/100\n",
      " - 11s - loss: 0.0464 - f1_m: 0.9875 - val_loss: 0.0585 - val_f1_m: 0.9787\n",
      "Epoch 75/100\n",
      " - 10s - loss: 0.0466 - f1_m: 0.9876 - val_loss: 0.0432 - val_f1_m: 0.9852\n",
      "Epoch 76/100\n",
      " - 10s - loss: 0.0505 - f1_m: 0.9874 - val_loss: 0.0495 - val_f1_m: 0.9866\n",
      "Epoch 77/100\n",
      " - 10s - loss: 0.0503 - f1_m: 0.9873 - val_loss: 0.0473 - val_f1_m: 0.9835\n",
      "Epoch 78/100\n",
      " - 11s - loss: 0.0467 - f1_m: 0.9875 - val_loss: 0.0504 - val_f1_m: 0.9840\n",
      "Epoch 79/100\n",
      " - 11s - loss: 0.0483 - f1_m: 0.9875 - val_loss: 0.0479 - val_f1_m: 0.9824\n",
      "Epoch 80/100\n",
      " - 11s - loss: 0.0458 - f1_m: 0.9875 - val_loss: 0.0495 - val_f1_m: 0.9827\n",
      "Epoch 81/100\n",
      " - 11s - loss: 0.0476 - f1_m: 0.9875 - val_loss: 0.0547 - val_f1_m: 0.9840\n",
      "Epoch 82/100\n",
      " - 11s - loss: 0.0477 - f1_m: 0.9876 - val_loss: 0.0586 - val_f1_m: 0.9787\n",
      "Epoch 83/100\n",
      " - 11s - loss: 0.0489 - f1_m: 0.9876 - val_loss: 0.0508 - val_f1_m: 0.9836\n",
      "Epoch 84/100\n",
      " - 11s - loss: 0.0502 - f1_m: 0.9877 - val_loss: 0.1959 - val_f1_m: 0.8961\n",
      "Epoch 85/100\n",
      " - 10s - loss: 0.0627 - f1_m: 0.9873 - val_loss: 0.0644 - val_f1_m: 0.9779\n",
      "Epoch 86/100\n",
      " - 11s - loss: 0.0596 - f1_m: 0.9878 - val_loss: 0.0384 - val_f1_m: 0.9857\n",
      "Epoch 87/100\n",
      " - 11s - loss: 0.0572 - f1_m: 0.9876 - val_loss: 0.0460 - val_f1_m: 0.9848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      " - 11s - loss: 0.0496 - f1_m: 0.9880 - val_loss: 0.0440 - val_f1_m: 0.9837\n",
      "Epoch 89/100\n",
      " - 11s - loss: 0.0543 - f1_m: 0.9880 - val_loss: 0.0428 - val_f1_m: 0.9835\n",
      "Epoch 90/100\n",
      " - 10s - loss: 0.0650 - f1_m: 0.9879 - val_loss: 0.0490 - val_f1_m: 0.9825\n",
      "Epoch 91/100\n",
      " - 11s - loss: 0.0555 - f1_m: 0.9878 - val_loss: 0.0574 - val_f1_m: 0.9828\n",
      "Epoch 92/100\n",
      " - 11s - loss: 0.0525 - f1_m: 0.9880 - val_loss: 0.0597 - val_f1_m: 0.9772\n",
      "Epoch 93/100\n",
      " - 11s - loss: 0.0480 - f1_m: 0.9880 - val_loss: 0.0401 - val_f1_m: 0.9857\n",
      "Epoch 94/100\n",
      " - 10s - loss: 0.0477 - f1_m: 0.9877 - val_loss: 0.0531 - val_f1_m: 0.9828\n",
      "Epoch 95/100\n",
      " - 11s - loss: 0.0455 - f1_m: 0.9882 - val_loss: 0.0481 - val_f1_m: 0.9807\n",
      "Epoch 96/100\n",
      " - 10s - loss: 0.0634 - f1_m: 0.9877 - val_loss: 0.0404 - val_f1_m: 0.9858\n",
      "Epoch 97/100\n",
      " - 10s - loss: 0.0822 - f1_m: 0.9876 - val_loss: 0.0488 - val_f1_m: 0.9808\n",
      "Epoch 98/100\n",
      " - 10s - loss: 0.0595 - f1_m: 0.9877 - val_loss: 0.0501 - val_f1_m: 0.9823\n",
      "Epoch 99/100\n",
      " - 11s - loss: 0.0477 - f1_m: 0.9877 - val_loss: 0.0570 - val_f1_m: 0.9836\n",
      "Epoch 100/100\n",
      " - 10s - loss: 0.0489 - f1_m: 0.9879 - val_loss: 0.0602 - val_f1_m: 0.9772\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "               metrics=[f1_m])\n",
    "\n",
    "train_history=model.fit(X_train0, y_train0_0, validation_split=0.3, epochs=100, batch_size=200, verbose=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9448885505223533\n",
      "0.9894812470736394\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict_classes(X_test0) \n",
    "\n",
    "y_true=y_test0.ans\n",
    "print(f1_score(y_true, prediction, average='binary'))\n",
    "print(accuracy_score(y_true, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict Y\n",
    "y_pred=model.predict_classes(X_test_more)\n",
    "y_ans = pd.DataFrame(y_pred,columns=['predict'],index=y_test.index)\n",
    "y_output=pd.merge(y_test,y_ans,left_index=True,right_index=True)\n",
    "\n",
    "y_output.to_csv(path+'\\grade\\B\\y_output_MLP_B_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分 train0 test0\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X_train_more, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "oversample = BorderlineSMOTE()\n",
    "X3, y3 = oversample.fit_resample(X_train0, y_train0.ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16554\n",
      "(385496,)\n",
      "368942\n",
      "(737884,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train0.ans.sum())\n",
    "print(y_train0.ans.shape)\n",
    "print(y3.sum())\n",
    "print(y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0=X3\n",
    "y_train0=y3\n",
    "y_train0_0 = keras.utils.to_categorical(y_train0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.to_csv(path+'\\grade\\A\\X3.csv')\n",
    "y3.to_csv(path+'\\grade\\A\\y3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=70, units=48)`\n",
      "  \n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=48, units=48)`\n",
      "  \"\"\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=48, units=36)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=36, units=36)`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=36, units=12)`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=12, units=12)`\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=12, units=2)`\n"
     ]
    }
   ],
   "source": [
    "model01 = Sequential() #建立模型\n",
    "model01.add(Dense(input_dim = 70, output_dim = 48)) #添加输入层、隐藏层的连接\n",
    "model01.add(Activation('tanh')) #以Relu函数为激活函数\n",
    "\n",
    "model01.add(Dense(input_dim = 48, output_dim = 48)) #添加隐藏层、隐藏层的连接\n",
    "model01.add(Activation('relu')) #以Relu函数为激活函数\n",
    "model01.add(Dropout(0.2))\n",
    "\n",
    "model01.add(Dense(input_dim = 48, output_dim = 36)) #添加隐藏层、隐藏层的连接\n",
    "model01.add(Activation('relu')) #以Relu函数为激活函数\n",
    "model01.add(Dropout(0.2))\n",
    "model01.add(Dense(input_dim = 36, output_dim = 36)) #添加隐藏层、隐藏层的连接\n",
    "model01.add(Activation('relu')) #以Relu函数为激活函数\n",
    "\n",
    "model01.add(Dense(input_dim = 36, output_dim = 12)) #添加隐藏层、隐藏层的连接\n",
    "model01.add(Activation('relu')) #以Relu函数为激活函数\n",
    "model01.add(Dense(input_dim = 12, output_dim = 12)) #添加隐藏层、隐藏层的连接\n",
    "model01.add(Activation('relu')) #以Relu函数为激活函数\n",
    "\n",
    "\n",
    "model01.add(Dense(input_dim = 12, output_dim = 2)) #添加隐藏层、输出层的连接\n",
    "model01.add(Activation('sigmoid')) #以sigmoid函数为激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 516518 samples, validate on 221366 samples\n",
      "Epoch 1/70\n",
      " - 8s - loss: 0.0809 - f1_m: 0.9743 - val_loss: 0.0490 - val_f1_m: 0.9808\n",
      "Epoch 2/70\n",
      " - 8s - loss: 0.0498 - f1_m: 0.9853 - val_loss: 0.0319 - val_f1_m: 0.9865\n",
      "Epoch 3/70\n",
      " - 8s - loss: 0.0434 - f1_m: 0.9874 - val_loss: 0.0275 - val_f1_m: 0.9894\n",
      "Epoch 4/70\n",
      " - 7s - loss: 0.0406 - f1_m: 0.9885 - val_loss: 0.0285 - val_f1_m: 0.9891\n",
      "Epoch 5/70\n",
      " - 8s - loss: 0.0388 - f1_m: 0.9892 - val_loss: 0.0211 - val_f1_m: 0.9921\n",
      "Epoch 6/70\n",
      " - 8s - loss: 0.0373 - f1_m: 0.9897 - val_loss: 0.0259 - val_f1_m: 0.9900\n",
      "Epoch 7/70\n",
      " - 8s - loss: 0.0360 - f1_m: 0.9900 - val_loss: 0.0237 - val_f1_m: 0.9919\n",
      "Epoch 8/70\n",
      " - 8s - loss: 0.0354 - f1_m: 0.9905 - val_loss: 0.0261 - val_f1_m: 0.9911\n",
      "Epoch 9/70\n",
      " - 8s - loss: 0.0343 - f1_m: 0.9907 - val_loss: 0.0155 - val_f1_m: 0.9939\n",
      "Epoch 10/70\n",
      " - 8s - loss: 0.0337 - f1_m: 0.9909 - val_loss: 0.0212 - val_f1_m: 0.9924\n",
      "Epoch 11/70\n",
      " - 7s - loss: 0.0329 - f1_m: 0.9910 - val_loss: 0.0151 - val_f1_m: 0.9942\n",
      "Epoch 12/70\n",
      " - 7s - loss: 0.0323 - f1_m: 0.9913 - val_loss: 0.0183 - val_f1_m: 0.9926\n",
      "Epoch 13/70\n",
      " - 7s - loss: 0.0314 - f1_m: 0.9914 - val_loss: 0.0151 - val_f1_m: 0.9945\n",
      "Epoch 14/70\n",
      " - 7s - loss: 0.0316 - f1_m: 0.9915 - val_loss: 0.0150 - val_f1_m: 0.9944\n",
      "Epoch 15/70\n",
      " - 8s - loss: 0.0313 - f1_m: 0.9917 - val_loss: 0.0134 - val_f1_m: 0.9952\n",
      "Epoch 16/70\n",
      " - 8s - loss: 0.0313 - f1_m: 0.9918 - val_loss: 0.0230 - val_f1_m: 0.9911\n",
      "Epoch 17/70\n",
      " - 8s - loss: 0.0311 - f1_m: 0.9919 - val_loss: 0.0176 - val_f1_m: 0.9941\n",
      "Epoch 18/70\n",
      " - 8s - loss: 0.0309 - f1_m: 0.9919 - val_loss: 0.0159 - val_f1_m: 0.9947\n",
      "Epoch 19/70\n",
      " - 7s - loss: 0.0305 - f1_m: 0.9920 - val_loss: 0.0156 - val_f1_m: 0.9941\n",
      "Epoch 20/70\n",
      " - 7s - loss: 0.0303 - f1_m: 0.9919 - val_loss: 0.0181 - val_f1_m: 0.9931\n",
      "Epoch 21/70\n",
      " - 7s - loss: 0.0305 - f1_m: 0.9920 - val_loss: 0.0119 - val_f1_m: 0.9957\n",
      "Epoch 22/70\n",
      " - 8s - loss: 0.0301 - f1_m: 0.9920 - val_loss: 0.0189 - val_f1_m: 0.9916\n",
      "Epoch 23/70\n",
      " - 8s - loss: 0.0304 - f1_m: 0.9921 - val_loss: 0.0145 - val_f1_m: 0.9945\n",
      "Epoch 24/70\n",
      " - 8s - loss: 0.0296 - f1_m: 0.9922 - val_loss: 0.0123 - val_f1_m: 0.9950\n",
      "Epoch 25/70\n",
      " - 8s - loss: 0.0298 - f1_m: 0.9922 - val_loss: 0.0118 - val_f1_m: 0.9956\n",
      "Epoch 26/70\n",
      " - 7s - loss: 0.0298 - f1_m: 0.9923 - val_loss: 0.0158 - val_f1_m: 0.9944\n",
      "Epoch 27/70\n",
      " - 7s - loss: 0.0293 - f1_m: 0.9923 - val_loss: 0.0192 - val_f1_m: 0.9932\n",
      "Epoch 28/70\n",
      " - 7s - loss: 0.0301 - f1_m: 0.9924 - val_loss: 0.0174 - val_f1_m: 0.9940\n",
      "Epoch 29/70\n",
      " - 8s - loss: 0.0292 - f1_m: 0.9924 - val_loss: 0.0172 - val_f1_m: 0.9943\n",
      "Epoch 30/70\n",
      " - 8s - loss: 0.0299 - f1_m: 0.9926 - val_loss: 0.0145 - val_f1_m: 0.9948\n",
      "Epoch 31/70\n",
      " - 8s - loss: 0.0294 - f1_m: 0.9925 - val_loss: 0.0114 - val_f1_m: 0.9957\n",
      "Epoch 32/70\n",
      " - 8s - loss: 0.0328 - f1_m: 0.9920 - val_loss: 0.0130 - val_f1_m: 0.9949\n",
      "Epoch 33/70\n",
      " - 8s - loss: 0.0298 - f1_m: 0.9925 - val_loss: 0.0107 - val_f1_m: 0.9958\n",
      "Epoch 34/70\n",
      " - 8s - loss: 0.0285 - f1_m: 0.9925 - val_loss: 0.0143 - val_f1_m: 0.9946\n",
      "Epoch 35/70\n",
      " - 7s - loss: 0.0290 - f1_m: 0.9924 - val_loss: 0.0135 - val_f1_m: 0.9949\n",
      "Epoch 36/70\n",
      " - 7s - loss: 0.0307 - f1_m: 0.9925 - val_loss: 0.0156 - val_f1_m: 0.9941\n",
      "Epoch 37/70\n",
      " - 8s - loss: 0.0309 - f1_m: 0.9925 - val_loss: 0.0199 - val_f1_m: 0.9926\n",
      "Epoch 38/70\n",
      " - 8s - loss: 0.0300 - f1_m: 0.9925 - val_loss: 0.0186 - val_f1_m: 0.9945\n",
      "Epoch 39/70\n",
      " - 8s - loss: 0.0334 - f1_m: 0.9920 - val_loss: 0.0100 - val_f1_m: 0.9961\n",
      "Epoch 40/70\n",
      " - 8s - loss: 0.0317 - f1_m: 0.9923 - val_loss: 0.0107 - val_f1_m: 0.9958\n",
      "Epoch 41/70\n",
      " - 8s - loss: 0.0304 - f1_m: 0.9926 - val_loss: 0.0084 - val_f1_m: 0.9963\n",
      "Epoch 42/70\n",
      " - 7s - loss: 0.0320 - f1_m: 0.9924 - val_loss: 0.0135 - val_f1_m: 0.9950\n",
      "Epoch 43/70\n",
      " - 8s - loss: 0.0295 - f1_m: 0.9926 - val_loss: 0.0247 - val_f1_m: 0.9898\n",
      "Epoch 44/70\n",
      " - 8s - loss: 0.0297 - f1_m: 0.9924 - val_loss: 0.0151 - val_f1_m: 0.9939\n",
      "Epoch 45/70\n",
      " - 8s - loss: 0.0310 - f1_m: 0.9923 - val_loss: 0.0108 - val_f1_m: 0.9956\n",
      "Epoch 46/70\n",
      " - 8s - loss: 0.0298 - f1_m: 0.9924 - val_loss: 0.0190 - val_f1_m: 0.9919\n",
      "Epoch 47/70\n",
      " - 8s - loss: 0.0294 - f1_m: 0.9928 - val_loss: 0.0072 - val_f1_m: 0.9972\n",
      "Epoch 48/70\n",
      " - 7s - loss: 0.0289 - f1_m: 0.9927 - val_loss: 0.0112 - val_f1_m: 0.9958\n",
      "Epoch 49/70\n",
      " - 8s - loss: 0.0294 - f1_m: 0.9928 - val_loss: 0.0136 - val_f1_m: 0.9945\n",
      "Epoch 50/70\n",
      " - 7s - loss: 0.0287 - f1_m: 0.9928 - val_loss: 0.0159 - val_f1_m: 0.9945\n",
      "Epoch 51/70\n",
      " - 8s - loss: 0.0284 - f1_m: 0.9927 - val_loss: 0.0133 - val_f1_m: 0.9951\n",
      "Epoch 52/70\n",
      " - 7s - loss: 0.0295 - f1_m: 0.9925 - val_loss: 0.0139 - val_f1_m: 0.9947\n",
      "Epoch 53/70\n",
      " - 7s - loss: 0.0291 - f1_m: 0.9926 - val_loss: 0.0147 - val_f1_m: 0.9943\n",
      "Epoch 54/70\n",
      " - 8s - loss: 0.0298 - f1_m: 0.9926 - val_loss: 0.0123 - val_f1_m: 0.9956\n",
      "Epoch 55/70\n",
      " - 7s - loss: 0.0296 - f1_m: 0.9927 - val_loss: 0.0140 - val_f1_m: 0.9945\n",
      "Epoch 56/70\n",
      " - 7s - loss: 0.0298 - f1_m: 0.9926 - val_loss: 0.0127 - val_f1_m: 0.9953\n",
      "Epoch 57/70\n",
      " - 7s - loss: 0.0293 - f1_m: 0.9926 - val_loss: 0.0173 - val_f1_m: 0.9930\n",
      "Epoch 58/70\n",
      " - 8s - loss: 0.0292 - f1_m: 0.9926 - val_loss: 0.0133 - val_f1_m: 0.9945\n",
      "Epoch 59/70\n",
      " - 8s - loss: 0.0299 - f1_m: 0.9926 - val_loss: 0.0159 - val_f1_m: 0.9942\n",
      "Epoch 60/70\n",
      " - 8s - loss: 0.0293 - f1_m: 0.9926 - val_loss: 0.0112 - val_f1_m: 0.9964\n",
      "Epoch 61/70\n",
      " - 8s - loss: 0.0291 - f1_m: 0.9928 - val_loss: 0.0354 - val_f1_m: 0.9861\n",
      "Epoch 62/70\n",
      " - 7s - loss: 0.0301 - f1_m: 0.9928 - val_loss: 0.0142 - val_f1_m: 0.9952\n",
      "Epoch 63/70\n",
      " - 8s - loss: 0.0299 - f1_m: 0.9927 - val_loss: 0.0168 - val_f1_m: 0.9927\n",
      "Epoch 64/70\n",
      " - 8s - loss: 0.0293 - f1_m: 0.9928 - val_loss: 0.0079 - val_f1_m: 0.9971\n",
      "Epoch 65/70\n",
      " - 8s - loss: 0.0298 - f1_m: 0.9927 - val_loss: 0.0164 - val_f1_m: 0.9934\n",
      "Epoch 66/70\n",
      " - 8s - loss: 0.0315 - f1_m: 0.9926 - val_loss: 0.0164 - val_f1_m: 0.9940\n",
      "Epoch 67/70\n",
      " - 7s - loss: 0.0305 - f1_m: 0.9927 - val_loss: 0.0139 - val_f1_m: 0.9951\n",
      "Epoch 68/70\n",
      " - 8s - loss: 0.0301 - f1_m: 0.9926 - val_loss: 0.0165 - val_f1_m: 0.9941\n",
      "Epoch 69/70\n",
      " - 8s - loss: 0.0295 - f1_m: 0.9928 - val_loss: 0.0107 - val_f1_m: 0.9959\n",
      "Epoch 70/70\n",
      " - 8s - loss: 0.0304 - f1_m: 0.9926 - val_loss: 0.0726 - val_f1_m: 0.9632\n"
     ]
    }
   ],
   "source": [
    "model01.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "               metrics=[f1_m])\n",
    "\n",
    "train_history=model01.fit(X_train0, y_train0_0, validation_split=0.3, epochs=70, batch_size=200, verbose=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732544221306024\n",
      "0.9901114408450412\n"
     ]
    }
   ],
   "source": [
    "prediction=model01.predict_classes(X_test0) \n",
    "\n",
    "y_true=y_test0.ans\n",
    "print(f1_score(y_true, prediction, average='binary'))\n",
    "print(accuracy_score(y_true, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分 train0 test0\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X_train_more, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE\n",
    "oversample = SVMSMOTE()\n",
    "X1, y1 = oversample.fit_resample(X_train0, y_train0.ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.to_csv(path+'\\grade\\A\\X1.csv')\n",
    "y1.to_csv(path+'\\grade\\A\\y1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16554\n",
      "(385496,)\n",
      "368942\n",
      "(737884,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train0.ans.sum())\n",
    "print(y_train0.ans.shape)\n",
    "print(y1.sum())\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0=X1\n",
    "y_train0=y1\n",
    "y_train0_0 = keras.utils.to_categorical(y_train0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=70, units=48)`\n",
      "  \n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=48, units=48)`\n",
      "  \"\"\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=48, units=36)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=36, units=36)`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=36, units=12)`\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=12, units=12)`\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=12, units=2)`\n"
     ]
    }
   ],
   "source": [
    "model02 = Sequential() #建立模型\n",
    "model02.add(Dense(input_dim = 70, output_dim = 48)) #添加输入层、隐藏层的连接\n",
    "model02.add(Activation('tanh')) #以Relu函数为激活函数\n",
    "\n",
    "model02.add(Dense(input_dim = 48, output_dim = 48)) #添加隐藏层、隐藏层的连接\n",
    "model02.add(Activation('relu')) #以Relu函数为激活函数\n",
    "model02.add(Dropout(0.2))\n",
    "\n",
    "model02.add(Dense(input_dim = 48, output_dim = 36)) #添加隐藏层、隐藏层的连接\n",
    "model02.add(Activation('relu')) #以Relu函数为激活函数\n",
    "model02.add(Dropout(0.2))\n",
    "model02.add(Dense(input_dim = 36, output_dim = 36)) #添加隐藏层、隐藏层的连接\n",
    "model02.add(Activation('relu')) #以Relu函数为激活函数\n",
    "\n",
    "model02.add(Dense(input_dim = 36, output_dim = 12)) #添加隐藏层、隐藏层的连接\n",
    "model02.add(Activation('relu')) #以Relu函数为激活函数\n",
    "model02.add(Dense(input_dim = 12, output_dim = 12)) #添加隐藏层、隐藏层的连接\n",
    "model02.add(Activation('relu')) #以Relu函数为激活函数\n",
    "\n",
    "\n",
    "model02.add(Dense(input_dim = 12, output_dim = 2)) #添加隐藏层、输出层的连接\n",
    "model02.add(Activation('sigmoid')) #以sigmoid函数为激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 516518 samples, validate on 221366 samples\n",
      "Epoch 1/70\n",
      " - 8s - loss: 0.0898 - f1_m: 0.9700 - val_loss: 0.1200 - val_f1_m: 0.9511\n",
      "Epoch 2/70\n",
      " - 7s - loss: 0.0566 - f1_m: 0.9829 - val_loss: 0.1355 - val_f1_m: 0.9446\n",
      "Epoch 3/70\n",
      " - 7s - loss: 0.0480 - f1_m: 0.9859 - val_loss: 0.1046 - val_f1_m: 0.9513\n",
      "Epoch 4/70\n",
      " - 7s - loss: 0.0437 - f1_m: 0.9874 - val_loss: 0.2595 - val_f1_m: 0.8837\n",
      "Epoch 5/70\n",
      " - 7s - loss: 0.0405 - f1_m: 0.9883 - val_loss: 0.2456 - val_f1_m: 0.8889\n",
      "Epoch 6/70\n",
      " - 7s - loss: 0.0391 - f1_m: 0.9888 - val_loss: 0.0740 - val_f1_m: 0.9710\n",
      "Epoch 7/70\n",
      " - 7s - loss: 0.0375 - f1_m: 0.9895 - val_loss: 0.2155 - val_f1_m: 0.9096\n",
      "Epoch 8/70\n",
      " - 7s - loss: 0.0369 - f1_m: 0.9898 - val_loss: 0.1219 - val_f1_m: 0.9535\n",
      "Epoch 9/70\n",
      " - 7s - loss: 0.0355 - f1_m: 0.9904 - val_loss: 0.1474 - val_f1_m: 0.9405\n",
      "Epoch 10/70\n",
      " - 7s - loss: 0.0353 - f1_m: 0.9906 - val_loss: 0.2157 - val_f1_m: 0.9135\n",
      "Epoch 11/70\n",
      " - 7s - loss: 0.0346 - f1_m: 0.9906 - val_loss: 0.1795 - val_f1_m: 0.9341\n",
      "Epoch 12/70\n",
      " - 7s - loss: 0.0342 - f1_m: 0.9909 - val_loss: 0.2022 - val_f1_m: 0.9208\n",
      "Epoch 13/70\n",
      " - 8s - loss: 0.0334 - f1_m: 0.9912 - val_loss: 0.2800 - val_f1_m: 0.9068\n",
      "Epoch 14/70\n",
      " - 8s - loss: 0.0330 - f1_m: 0.9913 - val_loss: 0.2186 - val_f1_m: 0.9287\n",
      "Epoch 15/70\n",
      " - 7s - loss: 0.0322 - f1_m: 0.9914 - val_loss: 0.2346 - val_f1_m: 0.9322\n",
      "Epoch 16/70\n",
      " - 7s - loss: 0.0316 - f1_m: 0.9916 - val_loss: 0.4054 - val_f1_m: 0.9158\n",
      "Epoch 17/70\n",
      " - 7s - loss: 0.0314 - f1_m: 0.9917 - val_loss: 0.2264 - val_f1_m: 0.9343\n",
      "Epoch 18/70\n",
      " - 7s - loss: 0.0312 - f1_m: 0.9918 - val_loss: 0.2094 - val_f1_m: 0.9302\n",
      "Epoch 19/70\n",
      " - 7s - loss: 0.0307 - f1_m: 0.9918 - val_loss: 0.2379 - val_f1_m: 0.9095\n",
      "Epoch 20/70\n",
      " - 7s - loss: 0.0306 - f1_m: 0.9919 - val_loss: 0.1947 - val_f1_m: 0.9305\n",
      "Epoch 21/70\n",
      " - 7s - loss: 0.0302 - f1_m: 0.9921 - val_loss: 0.2351 - val_f1_m: 0.9155\n",
      "Epoch 22/70\n",
      " - 7s - loss: 0.0305 - f1_m: 0.9919 - val_loss: 0.2310 - val_f1_m: 0.9158\n",
      "Epoch 23/70\n",
      " - 7s - loss: 0.0299 - f1_m: 0.9920 - val_loss: 0.3285 - val_f1_m: 0.8993\n",
      "Epoch 24/70\n",
      " - 7s - loss: 0.0294 - f1_m: 0.9923 - val_loss: 0.2353 - val_f1_m: 0.9310\n",
      "Epoch 25/70\n",
      " - 7s - loss: 0.0297 - f1_m: 0.9924 - val_loss: 0.4955 - val_f1_m: 0.8748\n",
      "Epoch 26/70\n",
      " - 7s - loss: 0.0294 - f1_m: 0.9924 - val_loss: 0.1754 - val_f1_m: 0.9410\n",
      "Epoch 27/70\n",
      " - 7s - loss: 0.0287 - f1_m: 0.9925 - val_loss: 0.3090 - val_f1_m: 0.8978\n",
      "Epoch 28/70\n",
      " - 7s - loss: 0.0289 - f1_m: 0.9925 - val_loss: 0.2100 - val_f1_m: 0.9259\n",
      "Epoch 29/70\n",
      " - 7s - loss: 0.0289 - f1_m: 0.9925 - val_loss: 0.1880 - val_f1_m: 0.9378\n",
      "Epoch 30/70\n",
      " - 7s - loss: 0.0288 - f1_m: 0.9926 - val_loss: 0.3751 - val_f1_m: 0.9180\n",
      "Epoch 31/70\n",
      " - 7s - loss: 0.0294 - f1_m: 0.9925 - val_loss: 0.3460 - val_f1_m: 0.8939\n",
      "Epoch 32/70\n",
      " - 7s - loss: 0.0284 - f1_m: 0.9925 - val_loss: 0.3263 - val_f1_m: 0.8931\n",
      "Epoch 33/70\n",
      " - 7s - loss: 0.0284 - f1_m: 0.9926 - val_loss: 0.1784 - val_f1_m: 0.9353\n",
      "Epoch 34/70\n",
      " - 7s - loss: 0.0281 - f1_m: 0.9926 - val_loss: 0.5126 - val_f1_m: 0.8392\n",
      "Epoch 35/70\n",
      " - 7s - loss: 0.0283 - f1_m: 0.9927 - val_loss: 0.2023 - val_f1_m: 0.9253\n",
      "Epoch 36/70\n",
      " - 7s - loss: 0.0284 - f1_m: 0.9926 - val_loss: 0.4752 - val_f1_m: 0.8803\n",
      "Epoch 37/70\n",
      " - 7s - loss: 0.0285 - f1_m: 0.9926 - val_loss: 0.2620 - val_f1_m: 0.9189\n",
      "Epoch 38/70\n",
      " - 7s - loss: 0.0282 - f1_m: 0.9927 - val_loss: 0.1818 - val_f1_m: 0.9357\n",
      "Epoch 39/70\n",
      " - 7s - loss: 0.0283 - f1_m: 0.9927 - val_loss: 0.1729 - val_f1_m: 0.9376\n",
      "Epoch 40/70\n",
      " - 7s - loss: 0.0287 - f1_m: 0.9927 - val_loss: 0.2419 - val_f1_m: 0.9258\n",
      "Epoch 41/70\n",
      " - 7s - loss: 0.0286 - f1_m: 0.9927 - val_loss: 0.3363 - val_f1_m: 0.9103\n",
      "Epoch 42/70\n",
      " - 7s - loss: 0.0282 - f1_m: 0.9929 - val_loss: 0.2524 - val_f1_m: 0.9244\n",
      "Epoch 43/70\n",
      " - 7s - loss: 0.0290 - f1_m: 0.9929 - val_loss: 0.4620 - val_f1_m: 0.8798\n",
      "Epoch 44/70\n",
      " - 7s - loss: 0.0287 - f1_m: 0.9929 - val_loss: 0.3418 - val_f1_m: 0.9207\n",
      "Epoch 45/70\n",
      " - 7s - loss: 0.0298 - f1_m: 0.9926 - val_loss: 0.2861 - val_f1_m: 0.9042\n",
      "Epoch 46/70\n",
      " - 7s - loss: 0.0292 - f1_m: 0.9929 - val_loss: 0.3975 - val_f1_m: 0.8973\n",
      "Epoch 47/70\n",
      " - 7s - loss: 0.0286 - f1_m: 0.9929 - val_loss: 0.2896 - val_f1_m: 0.9189\n",
      "Epoch 48/70\n",
      " - 7s - loss: 0.0300 - f1_m: 0.9927 - val_loss: 0.2936 - val_f1_m: 0.9045\n",
      "Epoch 49/70\n",
      " - 7s - loss: 0.0298 - f1_m: 0.9928 - val_loss: 0.2758 - val_f1_m: 0.9163\n",
      "Epoch 50/70\n",
      " - 7s - loss: 0.0293 - f1_m: 0.9930 - val_loss: 0.2103 - val_f1_m: 0.9394\n",
      "Epoch 51/70\n",
      " - 7s - loss: 0.0289 - f1_m: 0.9930 - val_loss: 0.4646 - val_f1_m: 0.8980\n",
      "Epoch 52/70\n",
      " - 7s - loss: 0.0290 - f1_m: 0.9930 - val_loss: 0.5600 - val_f1_m: 0.8770\n",
      "Epoch 53/70\n",
      " - 8s - loss: 0.0281 - f1_m: 0.9930 - val_loss: 0.3152 - val_f1_m: 0.9304\n",
      "Epoch 54/70\n",
      " - 8s - loss: 0.0281 - f1_m: 0.9931 - val_loss: 0.2247 - val_f1_m: 0.9266\n",
      "Epoch 55/70\n",
      " - 8s - loss: 0.0285 - f1_m: 0.9929 - val_loss: 0.2343 - val_f1_m: 0.9220\n",
      "Epoch 56/70\n",
      " - 7s - loss: 0.0281 - f1_m: 0.9930 - val_loss: 0.2822 - val_f1_m: 0.9214\n",
      "Epoch 57/70\n",
      " - 7s - loss: 0.0289 - f1_m: 0.9930 - val_loss: 0.3384 - val_f1_m: 0.9168\n",
      "Epoch 58/70\n",
      " - 7s - loss: 0.0283 - f1_m: 0.9929 - val_loss: 0.4346 - val_f1_m: 0.8846\n",
      "Epoch 59/70\n",
      " - 7s - loss: 0.0282 - f1_m: 0.9932 - val_loss: 0.2949 - val_f1_m: 0.8993\n",
      "Epoch 60/70\n",
      " - 7s - loss: 0.0288 - f1_m: 0.9930 - val_loss: 0.3029 - val_f1_m: 0.9047\n",
      "Epoch 61/70\n",
      " - 7s - loss: 0.0285 - f1_m: 0.9930 - val_loss: 0.3223 - val_f1_m: 0.9009\n",
      "Epoch 62/70\n",
      " - 7s - loss: 0.0280 - f1_m: 0.9930 - val_loss: 0.4914 - val_f1_m: 0.8708\n",
      "Epoch 63/70\n",
      " - 7s - loss: 0.0284 - f1_m: 0.9930 - val_loss: 0.2023 - val_f1_m: 0.9248\n",
      "Epoch 64/70\n",
      " - 7s - loss: 0.0285 - f1_m: 0.9931 - val_loss: 0.4487 - val_f1_m: 0.9137\n",
      "Epoch 65/70\n",
      " - 7s - loss: 0.0280 - f1_m: 0.9931 - val_loss: 0.2055 - val_f1_m: 0.9269\n",
      "Epoch 66/70\n",
      " - 7s - loss: 0.0285 - f1_m: 0.9931 - val_loss: 0.2460 - val_f1_m: 0.9226\n",
      "Epoch 67/70\n",
      " - 7s - loss: 0.0297 - f1_m: 0.9929 - val_loss: 0.2570 - val_f1_m: 0.9084\n",
      "Epoch 68/70\n",
      " - 7s - loss: 0.0310 - f1_m: 0.9930 - val_loss: 0.7089 - val_f1_m: 0.9075\n",
      "Epoch 69/70\n",
      " - 7s - loss: 0.0326 - f1_m: 0.9930 - val_loss: 0.2631 - val_f1_m: 0.9090\n",
      "Epoch 70/70\n",
      " - 7s - loss: 0.0297 - f1_m: 0.9931 - val_loss: 0.2608 - val_f1_m: 0.9156\n"
     ]
    }
   ],
   "source": [
    "model02.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "               metrics=[f1_m])\n",
    "\n",
    "train_history=model02.fit(X_train0, y_train0_0, validation_split=0.3, epochs=70, batch_size=200, verbose=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888465204957102\n",
      "0.990287836968477\n"
     ]
    }
   ],
   "source": [
    "prediction=model02.predict_classes(X_test0) \n",
    "\n",
    "y_true=y_test0.ans\n",
    "print(f1_score(y_true, prediction, average='binary'))\n",
    "print(accuracy_score(y_true, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict Y\n",
    "y_pred=model02.predict_classes(X_test_more)\n",
    "y_ans = pd.DataFrame(y_pred,columns=['predict'],index=y_test.index)\n",
    "y_output=pd.merge(y_test,y_ans,left_index=True,right_index=True)\n",
    "\n",
    "y_output.to_csv(path+'\\grade\\A\\y_output_MLP_A_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
